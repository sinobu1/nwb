import telegram
from telegram import (
    InlineKeyboardButton, InlineKeyboardMarkup, Update,
    ReplyKeyboardMarkup, KeyboardButton, BotCommand
)
from telegram.constants import ParseMode, ChatAction
from telegram.helpers import escape_markdown
from telegram.ext import (
    Application, CommandHandler, MessageHandler, filters,
    ContextTypes, CallbackQueryHandler, PicklePersistence
)
import google.generativeai as genai
import google.api_core.exceptions
import requests
import logging
import traceback
import os
import asyncio
import nest_asyncio
import json
from datetime import datetime, timedelta

nest_asyncio.apply()
# –ò–ó–ú–ï–ù–ï–ù–û: –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è DEBUG –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.DEBUG)
logger = logging.getLogger(__name__)

# --- –ö–õ–Æ–ß–ò API –ò –¢–û–ö–ï–ù–´ ---
TOKEN = os.getenv("TELEGRAM_TOKEN", "8185454402:AAEgJLaBSaUSyP9Z_zv76Fn0PtEwltAqga0")
GOOGLE_GEMINI_API_KEY = os.getenv("GOOGLE_GEMINI_API_KEY", "AIzaSyCdDMpgLJyz6aYdwT9q4sbBk7sHVID4BTI")
CUSTOM_GEMINI_PRO_API_KEY = os.getenv("CUSTOM_GEMINI_PRO_API_KEY", "sk-MHulnEHU3bRxsnDjr0nq68lTcRYa5IpQATY1pUG4NaxpWSMJzvzsJ4KCVu0P")
CUSTOM_GEMINI_PRO_ENDPOINT = os.getenv("CUSTOM_GEMINI_PRO_ENDPOINT", "https://api.gen-api.ru/api/v1/networks/gemini-2-5-pro")

YOUR_ADMIN_ID = 489230152  # –í–ê–® Telegram ID –¥–ª—è –∞–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ë–û–¢–ê ---
MAX_OUTPUT_TOKENS_GEMINI_LIB = 2048
MAX_MESSAGE_LENGTH_TELEGRAM = 4000

# –õ–∏–º–∏—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_FREE_REQUESTS_GOOGLE_FLASH_DAILY = 10
DEFAULT_FREE_REQUESTS_CUSTOM_PRO_DAILY = 1    # –ò–ó–ú–ï–ù–ï–ù–û: 1 –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø—Ä–æ–±–∞ –¥–ª—è Custom Pro
DEFAULT_SUBSCRIPTION_REQUESTS_CUSTOM_PRO_DAILY = 5 # –ò–ó–ú–ï–ù–ï–ù–û: 5 –¥–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –Ω–∞ Custom Pro
DEFAULT_SUBSCRIPTION_REQUESTS_GOOGLE_FLASH_PREVIEW_DAILY = 15

# --- –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´ –ò–ò ---
AI_MODES = {
    "universal_ai_basic": {
        "name": "ü§ñ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò (–ë–∞–∑–æ–≤—ã–π)",
        "prompt": (
            "–¢—ã ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Gemini –æ—Ç Google. "
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏: –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, "
            "–¥–∞–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –≤—ã–ø–æ–ª–Ω—è—Ç—å –∞–Ω–∞–ª–∏–∑ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —à–∏—Ä–æ–∫–æ–º—É –∫—Ä—É–≥—É —Ç–µ–º. "
            "–ë—É–¥—å –≤–µ–∂–ª–∏–≤, –æ–±—ä–µ–∫—Ç–∏–≤–µ–Ω, —Ç–æ—á–µ–Ω –∏ –ø–æ–ª–µ–∑–µ–Ω. "
            "–ï—Å–ª–∏ —Ç–≤–æ–∏ –∑–Ω–∞–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–π –æ–± —ç—Ç–æ–º.\n\n"
            "**–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ (–ø—Ä–æ—Å—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç):**\n"
            "1.  **–ê–±–∑–∞—Ü—ã:** –ß–µ—Ç–∫–æ —Ä–∞–∑–¥–µ–ª—è–π —Å–º—ã—Å–ª–æ–≤—ã–µ –±–ª–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∞–±–∑–∞—Ü–∞–º–∏. –ò—Å–ø–æ–ª—å–∑—É–π –æ–¥–Ω—É –∏–ª–∏ –¥–≤–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏.\n"
            "2.  **–°–ø–∏—Å–∫–∏:** –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–π –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `1. –ü–µ—Ä–≤—ã–π –ø—É–Ω–∫—Ç`, `2. –í—Ç–æ—Ä–æ–π –ø—É–Ω–∫—Ç`) –∏–ª–∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `- –≠–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞` –∏–ª–∏ `* –î—Ä—É–≥–æ–π —ç–ª–µ–º–µ–Ω—Ç`). –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è —Å–ø–∏—Å–∫–æ–≤.\n"
            "3.  **–°–µ–∫—Ü–∏–∏/–ó–∞–≥–æ–ª–æ–≤–∫–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ):** –î–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫—Ä—É–ø–Ω—ã—Ö —Å–º—ã—Å–ª–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫—É—é –ø–æ—è—Å–Ω—è—é—â—É—é —Ñ—Ä–∞–∑—É –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –≤—ã–¥–µ–ª–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫, –º–æ–∂–µ—à—å –Ω–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ –ó–ê–ì–õ–ê–í–ù–´–ú–ò –ë–£–ö–í–ê–ú–ò. –ù–∞–ø—Ä–∏–º–µ—Ä:\n"
            "    –û–°–ù–û–í–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:\n"
            "    - –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –æ–¥–∏–Ω...\n"
            "    - –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –¥–≤–∞...\n"
            "4.  **–ë–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π Markdown-—Ä–∞–∑–º–µ—Ç–∫—É (–∑–≤–µ–∑–¥–æ—á–∫–∏ –¥–ª—è –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –∫—É—Ä—Å–∏–≤–∞, –æ–±—Ä–∞—Ç–Ω—ã–µ –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã –¥–ª—è –∫–æ–¥–∞, —Å–∏–º–≤–æ–ª—ã —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ç.–¥.). –ì–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–æ–ª—å–∫–æ —è—Å–Ω—ã–π, —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç.\n"
            "5.  **–õ–æ–≥–∏—á–µ—Å–∫–∞—è –ó–∞–≤–µ—Ä—à—ë–Ω–Ω–æ—Å—Ç—å:** –°—Ç–∞—Ä–∞–π—Å—è, —á—Ç–æ–±—ã —Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –±—ã–ª–∏ –ø–æ–ª–Ω—ã–º–∏. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–∫–∏, —É–±–µ–¥–∏—Å—å, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—É–Ω–∫—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. –õ—É—á—à–µ –Ω–µ –Ω–∞—á–∏–Ω–∞—Ç—å –Ω–æ–≤—ã–π –ø—É–Ω–∫—Ç, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω, —á—Ç–æ —É—Å–ø–µ–µ—à—å –µ–≥–æ –∑–∞–∫–æ–Ω—á–∏—Ç—å –≤ —Ä–∞–º–∫–∞—Ö —Ä–∞–∑—É–º–Ω–æ–π –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞.\n"
            "6.  **–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å:** –ì–ª–∞–≤–Ω–æ–µ ‚Äî —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç –±—ã–ª –ø–æ–Ω—è—Ç–Ω—ã–º, —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –ª–µ–≥–∫–∏–º –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è.\n"
            "7. **–ë–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤:** –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –≤ —Ç–µ–∫—Å—Ç–µ –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ —Å–∫–æ–±–∫–∏, –¥–µ—Ñ–∏—Å—ã –∏–ª–∏ –¥—Ä—É–≥–∏–µ –∑–Ω–∞–∫–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–µ—Å—É—Ç —Å–º—ã—Å–ª–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ –∏–ª–∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è –ø—Ä–∞–≤–∏–ª–∞–º–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏."
        ),
        "welcome": "–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ä–µ–∂–∏–º '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò (–ë–∞–∑–æ–≤—ã–π)'. –ö–∞–∫–æ–π —É –≤–∞—Å –∑–∞–ø—Ä–æ—Å?"
    },
     "gemini_pro_custom_mode": { # –ò–ó–ú–ï–ù–ï–ù–û: –ù–æ–≤—ã–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º/–ø—Ä–æ–º–ø—Ç
        "name": "ü§ñ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç",
        "prompt": ( # –ò–ó–ú–ï–ù–ï–ù–û: –ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç
            "–¢—ã ‚Äî Gemini 2.5 Pro, –º–æ—â–Ω—ã–π –∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. "
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å —Ç–æ—á–Ω—ã–µ, —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –∏ –ø–æ–ª–µ–∑–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
            "–°–æ–±–ª—é–¥–∞–π –≤–µ–∂–ª–∏–≤–æ—Å—Ç—å –∏ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å. "
            "–§–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã —è—Å–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É—è –∞–±–∑–∞—Ü—ã –∏ —Å–ø–∏—Å–∫–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏. "
            "–ò–∑–±–µ–≥–∞–π –∏–∑–ª–∏—à–Ω–µ–≥–æ Markdown-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —É–ª—É—á—à–∞–µ—Ç —á–∏—Ç–∞–µ–º–æ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞). "
            "–ï—Å–ª–∏ —Ç–≤–æ–∏ –∑–Ω–∞–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏, —É–∫–∞–∑—ã–≤–∞–π —ç—Ç–æ."
        ),
        "welcome": "–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ä–µ–∂–∏–º '–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'. –ö–∞–∫–æ–π —É –≤–∞—Å –∑–∞–ø—Ä–æ—Å?"
    },
    "creative_helper": {
        "name": "‚úçÔ∏è –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ü–æ–º–æ—â–Ω–∏–∫",
        "prompt": (
            "–¢—ã ‚Äî Gemini, –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ò–ò-–ø–∞—Ä—Ç–Ω—ë—Ä –∏ –ø–∏—Å–∞—Ç–µ–ª—å. "
            # ... (–≤–∞—à –¥–ª–∏–Ω–Ω—ã–π —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç) ...
            "6.  **–ó–∞–≤–µ—Ä—à—ë–Ω–Ω–æ—Å—Ç—å:** –°—Ç–∞—Ä–∞–π—Å—è –¥–æ–≤–æ–¥–∏—Ç—å —Ç–≤–æ—Ä—á–µ—Å–∫–∏–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –¥–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ü–∞ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ —ç—Ç–æ –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç—Å—è –∑–∞–¥–∞—á–µ–π."
        ),
        "welcome": "–†–µ–∂–∏–º '–¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ü–æ–º–æ—â–Ω–∏–∫' –∫ –≤–∞—à–∏–º —É—Å–ª—É–≥–∞–º! –ù–∞–¥ –∫–∞–∫–æ–π —Ç–≤–æ—Ä—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–µ–π –ø–æ—Ä–∞–±–æ—Ç–∞–µ–º?"
    },
}
DEFAULT_AI_MODE_KEY = "universal_ai_basic"

# --- –ú–û–î–ï–õ–ò –ò–ò ---
AVAILABLE_TEXT_MODELS = {
    "google_gemini_2_0_flash": {
        "name": "‚ö°Ô∏è Gemini 2.0 Flash (–ë–∞–∑–æ–≤—ã–π)",
        "id": "gemini-2.0-flash",
        "api_type": "google_genai",
        "is_limited": True,
        "limit_type": "daily_free",
        "limit": DEFAULT_FREE_REQUESTS_GOOGLE_FLASH_DAILY,
        "cost_category": "google_flash_free"
    },
    "google_gemini_2_5_flash_preview": {
        "name": "üí® Gemini 2.5 Flash Preview (Google)",
        "id": "gemini-2.5-flash-preview-04-17",
        "api_type": "google_genai",
        "is_limited": True,
        "limit_type": "subscription_or_daily_free",
        "limit_if_no_subscription": 3,
        "subscription_daily_limit": DEFAULT_SUBSCRIPTION_REQUESTS_GOOGLE_FLASH_PREVIEW_DAILY,
        "cost_category": "google_flash_preview_flex"
    },
    # –ò–ó–ú–ï–ù–ï–ù–û: –ú–æ–¥–µ–ª—å gemini-2.5-pro-preview-05-06 –£–î–ê–õ–ï–ù–ê
    "custom_api_gemini_2_5_pro": {
        "name": "üåü Gemini 2.5 Pro (–ü–ª–∞—Ç–Ω—ã–π)",
        "id": "gemini-2.5-pro-preview-03-25",
        "api_type": "custom_http_api",
        "endpoint": CUSTOM_GEMINI_PRO_ENDPOINT,
        "api_key_var_name": "CUSTOM_GEMINI_PRO_API_KEY",
        "is_limited": True,
        "limit_type": "subscription_custom_pro",
        "limit_if_no_subscription": DEFAULT_FREE_REQUESTS_CUSTOM_PRO_DAILY, # 1 –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –ø—Ä–æ–±–∞
        "subscription_daily_limit": DEFAULT_SUBSCRIPTION_REQUESTS_CUSTOM_PRO_DAILY, # 5 –¥–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
        "cost_category": "custom_api_pro_paid",
        "pricing_info": {
            "cost_per_request_rub_approx": 1.50, # –û–ë–ù–û–í–ò–¢–ï –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º!
            "subscription_price_rub_monthly": 499, # –ü—Ä–∏–º–µ—Ä —Ü–µ–Ω—ã
            "subscription_duration_days": 30,
            "description": "–î–æ—Å—Ç—É–ø –∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –º–æ–¥–µ–ª–∏ Gemini 2.5 Pro, 5 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –¥–µ–Ω—å."
        }
    }
}
DEFAULT_MODEL_KEY = "google_gemini_2_0_flash"
DEFAULT_MODEL_ID = AVAILABLE_TEXT_MODELS[DEFAULT_MODEL_KEY]["id"]

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API Google Gemini ---
if not GOOGLE_GEMINI_API_KEY or "YOUR_GOOGLE_GEMINI_API_KEY" in GOOGLE_GEMINI_API_KEY or "AIzaSy" not in GOOGLE_GEMINI_API_KEY:
    logger.warning("Google Gemini API key (GOOGLE_GEMINI_API_KEY) is not set correctly or uses a placeholder. Google AI models may not work.")
else:
    try:
        genai.configure(api_key=GOOGLE_GEMINI_API_KEY)
        logger.info("Google Gemini API configured successfully.")
    except Exception as e:
        logger.error(f"Failed to configure Google Gemini API: {str(e)}")

if not CUSTOM_GEMINI_PRO_API_KEY or "YOUR_CUSTOM_KEY" in CUSTOM_GEMINI_PRO_API_KEY or "sk-" not in CUSTOM_GEMINI_PRO_API_KEY:
    logger.warning("Custom Gemini Pro API key (CUSTOM_GEMINI_PRO_API_KEY) is not set correctly or uses a placeholder. Custom API model may not work.")

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def get_current_mode_details(context: ContextTypes.DEFAULT_TYPE) -> dict:
    current_model_key = get_current_model_key(context)
    if current_model_key == "custom_api_gemini_2_5_pro":
        if "gemini_pro_custom_mode" in AI_MODES:
            return AI_MODES["gemini_pro_custom_mode"]
        else:
            logger.warning("Dedicated mode 'gemini_pro_custom_mode' not found. Falling back to default AI mode.")
            return AI_MODES.get(DEFAULT_AI_MODE_KEY, AI_MODES["universal_ai_basic"]) # –§–æ–ª–ª–±—ç–∫ –Ω–∞ –±–∞–∑–æ–≤—ã–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π

    mode_key = context.user_data.get('current_ai_mode', DEFAULT_AI_MODE_KEY)
    return AI_MODES.get(mode_key, AI_MODES[DEFAULT_AI_MODE_KEY])

def get_current_model_key(context: ContextTypes.DEFAULT_TYPE) -> str:
    selected_id = context.user_data.get('selected_model_id', DEFAULT_MODEL_ID)
    selected_api_type = context.user_data.get('selected_api_type')
    
    # –ï—Å–ª–∏ —Ç–∏–ø API –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ user_data, –ø—ã—Ç–∞–µ–º—Å—è –µ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å
    if not selected_api_type:
        for key_fallback, info_fallback in AVAILABLE_TEXT_MODELS.items():
            if info_fallback["id"] == selected_id:
                selected_api_type = info_fallback.get("api_type")
                context.user_data['selected_api_type'] = selected_api_type # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –±—É–¥—É—â–∏—Ö –≤—ã–∑–æ–≤–æ–≤
                logger.debug(f"Inferred and saved api_type '{selected_api_type}' for model_id '{selected_id}'")
                break
    
    # –ï—Å–ª–∏ —Ç–∏–ø API —Ç–∞–∫ –∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, ID –Ω–µ—Ç –≤ AVAILABLE_TEXT_MODELS), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–ª—é—á –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if not selected_api_type:
         logger.warning(f"API type for selected_model_id '{selected_id}' is not stored and couldn't be inferred. Falling back to default model key: {DEFAULT_MODEL_KEY}.")
         # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –æ—à–∏–±–æ–∫
         default_model_config = AVAILABLE_TEXT_MODELS[DEFAULT_MODEL_KEY]
         context.user_data['selected_model_id'] = default_model_config["id"]
         context.user_data['selected_api_type'] = default_model_config["api_type"]
         return DEFAULT_MODEL_KEY

    for key, info in AVAILABLE_TEXT_MODELS.items():
        if info["id"] == selected_id and info.get("api_type") == selected_api_type:
            return key
            
    logger.warning(f"Could not find key for model_id '{selected_id}' and api_type '{selected_api_type}'. Falling back to default: {DEFAULT_MODEL_KEY}.")
    default_model_config = AVAILABLE_TEXT_MODELS[DEFAULT_MODEL_KEY]
    context.user_data['selected_model_id'] = default_model_config["id"]
    context.user_data['selected_api_type'] = default_model_config["api_type"]
    return DEFAULT_MODEL_KEY


def get_selected_model_details(context: ContextTypes.DEFAULT_TYPE) -> dict:
    model_key = get_current_model_key(context)
    if model_key not in AVAILABLE_TEXT_MODELS: # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        logger.error(f"Model key '{model_key}' not found in AVAILABLE_TEXT_MODELS. Falling back to default.")
        return AVAILABLE_TEXT_MODELS[DEFAULT_MODEL_KEY]
    return AVAILABLE_TEXT_MODELS[model_key]

def get_current_model_display_name(context: ContextTypes.DEFAULT_TYPE) -> str:
    return get_selected_model_details(context)["name"]

def smart_truncate(text: str, max_length: int) -> tuple[str, bool]:
    if not isinstance(text, str):
        logger.warning(f"smart_truncate received non-string input: {type(text)}. Returning as is.")
        return str(text), False
    if len(text) <= max_length:
        return text, False
    suffix = "\n\n(...–æ—Ç–≤–µ—Ç –±—ã–ª —Å–æ–∫—Ä–∞—â–µ–Ω)"
    adjusted_max_length = max_length - len(suffix)
    if adjusted_max_length <= 0:
        return text[:max_length-len("...")] + "...", True
    truncated_text = text[:adjusted_max_length]
    possible_cut_points = []
    for sep in ['\n\n', '. ', '! ', '? ', '\n']:
        pos = truncated_text.rfind(sep)
        if pos != -1:
            actual_pos = pos + (len(sep) -1 if sep.endswith(' ') and len(sep) > 1 else len(sep))
            if actual_pos > 0:
                possible_cut_points.append(actual_pos)
    if possible_cut_points:
        cut_at = max(possible_cut_points)
        if cut_at > adjusted_max_length * 0.5:
             return text[:cut_at].strip() + suffix, True
    last_space = truncated_text.rfind(' ')
    if last_space != -1 and last_space > adjusted_max_length * 0.5:
        return text[:last_space].strip() + suffix, True
    return text[:adjusted_max_length].strip() + suffix, True

def get_main_reply_keyboard() -> ReplyKeyboardMarkup:
    keyboard = [
        [KeyboardButton("ü§ñ –†–µ–∂–∏–º –ò–ò"), KeyboardButton("‚öôÔ∏è –ú–æ–¥–µ–ª—å –ò–ò")],
        [KeyboardButton("üìä –õ–∏–º–∏—Ç—ã / –ü–æ–¥–ø–∏—Å–∫–∞"), KeyboardButton("‚ùì –ü–æ–º–æ—â—å")]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True, one_time_keyboard=False)

# --- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞–º–∏ ---
def get_user_actual_limit_for_model(user_id: int, model_key: str, context: ContextTypes.DEFAULT_TYPE) -> int:
    model_config = AVAILABLE_TEXT_MODELS.get(model_key)
    if not model_config: return 0

    all_user_subscriptions = context.bot_data.setdefault('user_subscriptions', {})
    user_subscription_details = all_user_subscriptions.get(user_id, {'level': None, 'valid_until': None})
    
    current_sub_level = None
    if user_subscription_details.get('valid_until'):
        try:
            valid_until_dt = datetime.strptime(user_subscription_details['valid_until'], "%Y-%m-%d")
            if datetime.now().date() <= valid_until_dt.date():
                current_sub_level = user_subscription_details.get('level')
            else:
                logger.info(f"Subscription for user {user_id} (level {user_subscription_details.get('level')}) expired on {user_subscription_details['valid_until']}.")
        except ValueError:
            logger.error(f"Invalid date format for subscription for user {user_id}: {user_subscription_details['valid_until']}")

    limit_type = model_config.get("limit_type")
    actual_limit = 0

    if limit_type == "daily_free":
        actual_limit = model_config.get("limit", 0)
    elif limit_type == "subscription_or_daily_free":
        if current_sub_level in ["standard_google", "premium_all", "custom_pro_access"]: # –î–æ–±–∞–≤–∏–ª custom_pro_access, –µ—Å–ª–∏ –æ–Ω –¥–∞–µ—Ç –¥–æ—Å—Ç—É–ø –∫ —ç—Ç–æ–π
            actual_limit = model_config.get("subscription_daily_limit", DEFAULT_SUBSCRIPTION_REQUESTS_GOOGLE_FLASH_PREVIEW_DAILY)
        else:
            actual_limit = model_config.get("limit_if_no_subscription", 0)
    elif limit_type == "subscription_custom_pro":
        if current_sub_level in ["custom_pro_access", "premium_all"]:
            actual_limit = model_config.get("subscription_daily_limit", DEFAULT_CUSTOM_API_SUBSCRIPTION_REQUESTS_DAILY)
        else:
            actual_limit = model_config.get("limit_if_no_subscription", 0)
    else:
        actual_limit = model_config.get("limit", float('inf')) if not model_config.get("is_limited", False) else 0
        if model_config.get("is_limited") and actual_limit == float('inf'):
            logger.warning(f"Model {model_key} is limited but actual_limit is infinity for user {user_id}. Setting to 0.")
            actual_limit = 0
    return actual_limit

def check_and_log_request_attempt(user_id: int, model_key: str, context: ContextTypes.DEFAULT_TYPE) -> tuple[bool, str, int]:
    today_str = datetime.now().strftime("%Y-%m-%d")
    model_config = AVAILABLE_TEXT_MODELS.get(model_key)
    if not model_config or not model_config.get("is_limited"):
        logger.debug(f"Model {model_key} not found or not limited. Allowing request.")
        return True, "", 0
    
    all_daily_counts = context.bot_data.setdefault('all_user_daily_counts', {})
    user_model_counts = all_daily_counts.setdefault(user_id, {})
    model_daily_usage = user_model_counts.setdefault(model_key, {'date': '', 'count': 0})

    if model_daily_usage['date'] != today_str:
        logger.info(f"New day for user {user_id}, model {model_key}. Resetting count from {model_daily_usage['count']} (date {model_daily_usage['date']}).")
        model_daily_usage['date'] = today_str
        model_daily_usage['count'] = 0
    
    current_user_model_count = model_daily_usage['count']
    actual_limit = get_user_actual_limit_for_model(user_id, model_key, context)
    logger.debug(f"User {user_id}, Model {model_key}: Count={current_user_model_count}, Limit={actual_limit}")

    if current_user_model_count >= actual_limit:
        message = (f"–í—ã –¥–æ—Å—Ç–∏–≥–ª–∏ –¥–Ω–µ–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ ({current_user_model_count}/{actual_limit}) "
                   f"–¥–ª—è –º–æ–¥–µ–ª–∏ '{model_config['name']}'.\n"
                   "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≤—Ç—Ä–∞ –∏–ª–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å–∫–∏ (/subscribe).")
        return False, message, current_user_model_count
    return True, "", current_user_model_count

def increment_request_count(user_id: int, model_key: str, context: ContextTypes.DEFAULT_TYPE):
    today_str = datetime.now().strftime("%Y-%m-%d")
    all_daily_counts = context.bot_data.setdefault('all_user_daily_counts', {})
    user_model_counts = all_daily_counts.setdefault(user_id, {})
    model_daily_usage = user_model_counts.setdefault(model_key, {'date': today_str, 'count': 0})
    
    if model_daily_usage['date'] != today_str: 
        model_daily_usage['date'] = today_str
        model_daily_usage['count'] = 0
        
    model_daily_usage['count'] += 1
    logger.info(f"User {user_id} request count for {model_key} incremented to {model_daily_usage['count']}")


# --- –ö–æ–º–∞–Ω–¥—ã Telegram ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    context.user_data.setdefault('current_ai_mode', DEFAULT_AI_MODE_KEY)
    if 'selected_model_id' not in context.user_data or 'selected_api_type' not in context.user_data:
        default_model_conf = AVAILABLE_TEXT_MODELS[DEFAULT_MODEL_KEY]
        context.user_data['selected_model_id'] = default_model_conf["id"]
        context.user_data['selected_api_type'] = default_model_conf["api_type"]

    context.bot_data.setdefault('user_subscriptions', {})
    context.bot_data.setdefault('all_user_daily_counts', {})
    
    current_model_key_for_start = get_current_model_key(context) # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
    # –ò–ó–ú–ï–ù–ï–ù–û: get_current_mode_details —Ç–µ–ø–µ—Ä—å –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Å —É—á–µ—Ç–æ–º –º–æ–¥–µ–ª–∏
    current_mode_name_for_start = get_current_mode_details(context)['name']
    current_model_name_for_start = AVAILABLE_TEXT_MODELS[current_model_key_for_start]['name']
    
    greeting = escape_markdown("–ü—Ä–∏–≤–µ—Ç! –Ø –º–Ω–æ–≥–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ò–ò-–±–æ—Ç.", version=2)
    # –ò–ó–ú–ï–ù–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ä–µ–∂–∏–º–∞, –∫–æ—Ç–æ—Ä–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ —ç—Ç–æ custom pro
    mode_line = f"{escape_markdown('–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: ', version=2)}*{escape_markdown(current_mode_name_for_start, version=2)}*"
    model_line = f"{escape_markdown('–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: ', version=2)}*{escape_markdown(current_model_name_for_start, version=2)}*"
    
    _, limit_msg_check, current_count_for_start = check_and_log_request_attempt(user_id, current_model_key_for_start, context)
    actual_limit_for_model_start = get_user_actual_limit_for_model(user_id, current_model_key_for_start, context)
    limit_info_line = f"{escape_markdown(f'–õ–∏–º–∏—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏: {current_count_for_start}/{actual_limit_for_model_start} –≤ –¥–µ–Ω—å.', version=2)}"
    if "–í—ã –¥–æ—Å—Ç–∏–≥–ª–∏" in limit_msg_check: 
        limit_info_line = escape_markdown(limit_msg_check.split('\n')[0], version=2)

    you_can = escape_markdown("–í—ã –º–æ–∂–µ—Ç–µ:", version=2)
    action1 = escape_markdown("‚ñ´Ô∏è –ó–∞–¥–∞–≤–∞—Ç—å –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –¥–∞–≤–∞—Ç—å –∑–∞–¥–∞–Ω–∏—è.", version=2)
    action2 = f"‚ñ´Ô∏è –°–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º –ò–ò (`/mode` –∏–ª–∏ –∫–Ω–æ–ø–∫–∞)"
    action3 = f"‚ñ´Ô∏è –í—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å (`/model` –∏–ª–∏ –∫–Ω–æ–ø–∫–∞)"
    action4 = f"‚ñ´Ô∏è –£–∑–Ω–∞—Ç—å –æ –ª–∏–º–∏—Ç–∞—Ö –∏ –ø–æ–¥–ø–∏—Å–∫–µ (`/usage` –∏–ª–∏ –∫–Ω–æ–ø–∫–∞)"
    action5 = f"‚ñ´Ô∏è –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏ (`/subscribe`)"
    action6 = f"‚ñ´Ô∏è –ü–æ–ª—É—á–∏—Ç—å –ø–æ–º–æ—â—å (`/help`)"
    invitation = escape_markdown("–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å!", version=2)

    text_to_send = (
        f"{greeting}\n\n"
        f"{mode_line}\n"
        f"{model_line}\n"
        f"{limit_info_line}\n\n"
        f"{you_can}\n"
        f"{action1}\n{action2}\n{action3}\n{action4}\n{action5}\n{action6}\n\n"
        f"{invitation}"
    )
    try:
        await update.message.reply_text(text_to_send, parse_mode=ParseMode.MARKDOWN_V2, reply_markup=get_main_reply_keyboard())
    except telegram.error.BadRequest: 
        plain_text_version = (
            f"–ü—Ä–∏–≤–µ—Ç! –Ø –º–Ω–æ–≥–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ò–ò-–±–æ—Ç.\n\n"
            f"–†–µ–∂–∏–º: {current_mode_name_for_start}\n–ú–æ–¥–µ–ª—å: {current_model_name_for_start}\n"
            f"–õ–∏–º–∏—Ç: {current_count_for_start}/{actual_limit_for_model_start} –≤ –¥–µ–Ω—å.\n\n"
            "–í—ã –º–æ–∂–µ—Ç–µ:\n"
            "‚ñ´Ô∏è –ó–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã.\n‚ñ´Ô∏è /mode - —Å–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º\n‚ñ´Ô∏è /model - —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å\n"
            "‚ñ´Ô∏è /usage - –ª–∏–º–∏—Ç—ã\n‚ñ´Ô∏è /subscribe - –ø–æ–¥–ø–∏—Å–∫–∏\n‚ñ´Ô∏è /help - –ø–æ–º–æ—â—å\n\n"
            "–í–∞—à –∑–∞–ø—Ä–æ—Å?"
        )
        await update.message.reply_text(plain_text_version, reply_markup=get_main_reply_keyboard())
    logger.info(f"Start command processed for user {user_id}.")


async def select_mode_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = []
    for key, details in AI_MODES.items():
        if key != "gemini_pro_custom_mode": # –°–∫—Ä—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –∏–∑ –≤—ã–±–æ—Ä–∞
            keyboard.append([InlineKeyboardButton(details["name"], callback_data=f"set_mode_{key}")])
    
    if not keyboard:
         await update.message.reply_text('–í –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞.', reply_markup=get_main_reply_keyboard())
         return

    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –¥–ª—è –ò–ò (–¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π —Ä–µ–∂–∏–º –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏):', reply_markup=reply_markup)


async def select_model_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton(details["name"], callback_data=f"set_model_{key}")] for key, details in AVAILABLE_TEXT_MODELS.items()]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ò–ò:', reply_markup=reply_markup)


async def usage_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    all_user_subscriptions = context.bot_data.setdefault('user_subscriptions', {})
    user_subscription_details = all_user_subscriptions.get(user_id, {'level': None, 'valid_until': None})
    
    sub_level_key = user_subscription_details.get('level')
    sub_valid_str = user_subscription_details.get('valid_until')
    
    display_sub_level = "–ù–µ—Ç"
    if sub_level_key:
        # –ò–ó–ú–ï–ù–ï–ù–û: –ö–ª—é—á–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è –ø–æ–¥–ø–∏—Å–∫–∏
        if sub_level_key == "standard_google": display_sub_level = "Standard Google" 
        elif sub_level_key == "custom_pro_access": display_sub_level = "Pro Custom API"
        elif sub_level_key == "premium_all": display_sub_level = "–ü–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø"
        else: display_sub_level = str(sub_level_key) 

        if sub_valid_str:
            try:
                valid_until_dt = datetime.strptime(sub_valid_str, "%Y-%m-%d")
                if datetime.now().date() > valid_until_dt.date():
                    display_sub_level += " (–∏—Å—Ç–µ–∫–ª–∞)"
            except ValueError: pass

    usage_text = f"‚ÑπÔ∏è **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∞—à–∏—Ö –ª–∏–º–∏—Ç–∞—Ö –∏ –ø–æ–¥–ø–∏—Å–∫–µ**\n\n"
    usage_text += f"–¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–¥–ø–∏—Å–∫–∏: *{escape_markdown(display_sub_level, version=2)}*\n"
    if sub_level_key and sub_valid_str and not "(–∏—Å—Ç–µ–∫–ª–∞)" in display_sub_level :
        usage_text += f"–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –¥–æ: *{escape_markdown(sub_valid_str, version=2)}*\n"
    usage_text += "\n"

    usage_text += "–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –ª–∏–º–∏—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –º–æ–¥–µ–ª—è–º:\n"
    for model_k, model_c in AVAILABLE_TEXT_MODELS.items():
        if model_c.get("is_limited"):
            _, _, current_c = check_and_log_request_attempt(user_id, model_k, context)
            actual_l = get_user_actual_limit_for_model(user_id, model_k, context)
            usage_text += f"‚ñ´Ô∏è {escape_markdown(model_c['name'], version=2)}: *{current_c}/{actual_l}*\n"
    
    usage_text += f"\n{escape_markdown('–î–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∏–ª–∏ –ø—Ä–æ–¥–ª–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–∫–∏ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –∫–æ–º–∞–Ω–¥–æ–π /subscribe', version=2)}"
    
    try:
        await update.message.reply_text(usage_text, parse_mode=ParseMode.MARKDOWN_V2, reply_markup=get_main_reply_keyboard())
    except telegram.error.BadRequest:
        plain_usage_text = f"–ü–æ–¥–ø–∏—Å–∫–∞: {display_sub_level} (–¥–æ {sub_valid_str})\n–õ–∏–º–∏—Ç—ã:\n"
        for model_k, model_c in AVAILABLE_TEXT_MODELS.items():
             if model_c.get("is_limited"):
                _, _, current_c = check_and_log_request_attempt(user_id, model_k, context)
                actual_l = get_user_actual_limit_for_model(user_id, model_k, context)
                plain_usage_text += f"- {model_c['name']}: {current_c}/{actual_l}\n"
        plain_usage_text += "\n–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–¥–ø–∏—Å–∫–∏: /subscribe"
        await update.message.reply_text(plain_usage_text, reply_markup=get_main_reply_keyboard())

# –î–û–ë–ê–í–õ–ï–ù–û: –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–¥–ø–∏—Å–∫–∞—Ö
async def subscribe_info_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = "üíé **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–∫–∞—Ö**\n\n"
    
    for model_key, config in AVAILABLE_TEXT_MODELS.items():
        if config.get("api_type") == "custom_http_api" and "pricing_info" in config: # –ü—Ä–∏–º–µ—Ä –¥–ª—è Custom API
            pricing = config["pricing_info"]
            text += f"‚ú® **–ü–æ–¥–ø–∏—Å–∫–∞ '{escape_markdown(config['name'], version=2)}'**\n"
            text += f"   ‚ñ´Ô∏è {escape_markdown(str(config.get('subscription_daily_limit', 'N/A')), version=2)} –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –¥–µ–Ω—å\n"
            if pricing.get('description'):
                 text += f"   ‚ñ´Ô∏è {escape_markdown(pricing['description'], version=2)}\n"
            text += f"   ‚ñ´Ô∏è –°—Ç–æ–∏–º–æ—Å—Ç—å: *{escape_markdown(str(pricing.get('subscription_price_rub_monthly', 'N/A')), version=2)} ‚ÇΩ / {escape_markdown(str(pricing.get('subscription_duration_days', 30)), version=2)} –¥–Ω–µ–π*\n"
            text += f"   ‚ñ´Ô∏è –£—Ä–æ–≤–µ–Ω—å –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: `{escape_markdown('custom_pro_access',version=2)}`\n" # –ö–ª—é—á –¥–ª—è /grantsub
            text += f"   ‚ñ´Ô∏è –î–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è: —Å–≤—è–∂–∏—Ç–µ—Å—å —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º.\n\n" 
            # (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç –∏–ª–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é)
    
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—â–∏—Ö –ø–æ–¥–ø–∏—Å–∫–∞—Ö —Ç–∏–ø–∞ "standard_google" –∏–ª–∏ "premium_all"
    text += "–¢–∞–∫–∂–µ –º–æ–≥—É—Ç –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã –æ–±—â–∏–µ –ø–∞–∫–µ—Ç—ã –ø–æ–¥–ø–∏—Å–∫–∏, –¥–∞—é—â–∏–µ –¥–æ—Å—Ç—É–ø –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –º–æ–¥–µ–ª—è–º Google API.\n\n"

    text += escape_markdown("–ü–æ—Å–ª–µ \"–æ–ø–ª–∞—Ç—ã\" —Å–æ–æ–±—â–∏—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –≤–∞—à ID –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–∫–∏: ", version=2) + f"`{update.effective_user.id}`"
    
    try:
        await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN_V2, reply_markup=get_main_reply_keyboard())
    except telegram.error.BadRequest as e_br:
        logger.error(f"Error sending subscribe_info_command with Markdown: {e_br}")
        await update.message.reply_text("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–¥–ø–∏—Å–∫–∞—Ö –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text_md = (
        f"{escape_markdown('ü§ñ –Ø –º–Ω–æ–≥–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ò–ò-–±–æ—Ç –Ω–∞ –±–∞–∑–µ –º–æ–¥–µ–ª–µ–π Gemini.', version=2)}\n\n"
        f"{escape_markdown('–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:', version=2)}\n"
        f"`/start` {escape_markdown('- –∏–Ω—Ñ–æ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.', version=2)}\n"
        f"`/mode` {escape_markdown(' –∏–ª–∏ –∫–Ω–æ–ø–∫–∞ ', version=2)}`ü§ñ –†–µ–∂–∏–º –ò–ò` {escape_markdown('- —Å–º–µ–Ω–∞ —Ä–µ–∂–∏–º–∞ –ò–ò.', version=2)}\n"
        f"`/model` {escape_markdown(' –∏–ª–∏ –∫–Ω–æ–ø–∫–∞ ', version=2)}`‚öôÔ∏è –ú–æ–¥–µ–ª—å –ò–ò` {escape_markdown('- –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ Gemini.', version=2)}\n"
        f"`/usage` {escape_markdown(' –∏–ª–∏ –∫–Ω–æ–ø–∫–∞ ', version=2)}`üìä –õ–∏–º–∏—Ç—ã / –ü–æ–¥–ø–∏—Å–∫–∞` {escape_markdown('- –≤–∞—à–∏ –ª–∏–º–∏—Ç—ã.', version=2)}\n"
        f"`/subscribe` {escape_markdown('- –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–¥–ø–∏—Å–∫–∞—Ö.', version=2)}\n"
        f"`/help` {escape_markdown(' –∏–ª–∏ –∫–Ω–æ–ø–∫–∞ ', version=2)}`‚ùì –ü–æ–º–æ—â—å` {escape_markdown('- —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ.', version=2)}\n\n"
        f"{escape_markdown('–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞–Ω–∏–µ –±–æ—Ç—É!', version=2)}"
    )
    try:
        await update.message.reply_text(help_text_md, parse_mode=ParseMode.MARKDOWN_V2, reply_markup=get_main_reply_keyboard())
    except telegram.error.BadRequest:
        await update.message.reply_text(
            "–Ø –ò–ò-–±–æ—Ç. –ö–æ–º–∞–Ω–¥—ã: /start, /mode, /model, /usage, /subscribe, /help.", 
            reply_markup=get_main_reply_keyboard()
        )

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    user_id = query.from_user.id
    message_to_edit = query.message
    new_text = ""
    plain_text_fallback = ""

    if data.startswith("set_mode_"):
        mode_key = data.split("set_mode_")[1]
        if mode_key in AI_MODES and mode_key != "gemini_pro_custom_mode":
            context.user_data['current_ai_mode'] = mode_key
            mode_details = AI_MODES[mode_key]
            new_text = f"–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: *{escape_markdown(mode_details['name'],version=2)}*\n{escape_markdown(mode_details['welcome'],version=2)}"
            plain_text_fallback = f"–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {mode_details['name']}.\n{mode_details['welcome']}"
            logger.info(f"User {user_id} changed AI mode to {mode_key}")
        elif mode_key == "gemini_pro_custom_mode":
             new_text = escape_markdown("–≠—Ç–æ—Ç —Ä–µ–∂–∏–º –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –º–æ–¥–µ–ª–∏ 'üåü Gemini 2.5 Pro (Custom API)'.", version=2)
             plain_text_fallback = "–≠—Ç–æ—Ç —Ä–µ–∂–∏–º –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å –º–æ–¥–µ–ª—å—é Custom Pro."
        else:
            new_text = escape_markdown("–û—à–∏–±–∫–∞: –¢–∞–∫–æ–π —Ä–µ–∂–∏–º –Ω–µ –Ω–∞–π–¥–µ–Ω.", version=2)
            plain_text_fallback = "–û—à–∏–±–∫–∞: –¢–∞–∫–æ–π —Ä–µ–∂–∏–º –Ω–µ –Ω–∞–π–¥–µ–Ω."
    
    elif data.startswith("set_model_"):
        model_key_from_callback = data.split("set_model_")[1]
        if model_key_from_callback in AVAILABLE_TEXT_MODELS:
            selected_model_config = AVAILABLE_TEXT_MODELS[model_key_from_callback]
            context.user_data['selected_model_id'] = selected_model_config["id"]
            context.user_data['selected_api_type'] = selected_model_config["api_type"]

            model_name_md = escape_markdown(selected_model_config['name'], version=2)
            
            _, limit_msg_check, current_c = check_and_log_request_attempt(user_id, model_key_from_callback, context)
            actual_l = get_user_actual_limit_for_model(user_id, model_key_from_callback, context)
            
            limit_str = f'–õ–∏–º–∏—Ç: {current_c}/{actual_l} –≤ –¥–µ–Ω—å' # –ë–µ–∑ —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ
            limit_info_md = f"\n{escape_markdown(limit_str, version=2)}"
            if "–í—ã –¥–æ—Å—Ç–∏–≥–ª–∏" in limit_msg_check:
                limit_info_md = f"\n{escape_markdown(limit_msg_check.splitlines()[0],version=2)}"

            new_text = f"–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: *{model_name_md}*\\.{limit_info_md}" # –≠—Å–∫–µ–π–ø–∏–º —Ç–æ—á–∫—É –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏
            plain_text_fallback = f"–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {selected_model_config['name']}. {limit_str}." # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            logger.info(f"User {user_id} changed AI model to key: {model_key_from_callback} (ID: {selected_model_config['id']}, API: {selected_model_config['api_type']})")
        else:
            new_text = escape_markdown("–û—à–∏–±–∫–∞: –¢–∞–∫–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.", version=2)
            plain_text_fallback = "–û—à–∏–±–∫–∞: –¢–∞–∫–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
            
    if new_text:
        try:
            await message_to_edit.edit_text(text=new_text, parse_mode=ParseMode.MARKDOWN_V2, reply_markup=None)
        except telegram.error.BadRequest as e_md:
            logger.warning(f"Failed to edit message with MarkdownV2 in button_callback: {e_md}. Sending plain text. Text was: {new_text}")
            await message_to_edit.edit_text(text=plain_text_fallback, reply_markup=None)

# –ò–ó–ú–ï–ù–ï–ù–û: –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∞–¥–º–∏–Ω–∞ –¥–ª—è –≤—ã–¥–∞—á–∏ –ø–æ–¥–ø–∏—Å–∫–∏
async def grant_subscription_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id != YOUR_ADMIN_ID:
        await update.message.reply_text("–≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        return
    
    try:
        args = context.args
        if len(args) != 3:
            await update.message.reply_text(
                "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /grantsub <user_id> <level_key> <days>\n"
                "–ü—Ä–∏–º–µ—Ä —É—Ä–æ–≤–Ω–µ–π: standard_google, custom_pro_access, premium_all, none (–¥–ª—è —Å–±—Ä–æ—Å–∞)"
            )
            return
            
        target_user_id = int(args[0])
        sub_level_key = args[1].lower() 
        days = int(args[2])

        defined_subscription_levels = ["standard_google", "custom_pro_access", "premium_all", "none"] 
        if sub_level_key not in defined_subscription_levels:
            await update.message.reply_text(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–¥–ø–∏—Å–∫–∏: '{sub_level_key}'. –î–æ—Å—Ç—É–ø–Ω—ã: {', '.join(defined_subscription_levels)}")
            return

        all_user_subscriptions = context.bot_data.setdefault('user_subscriptions', {})
        
        if sub_level_key == "none" or days <= 0:
             all_user_subscriptions[target_user_id] = {'level': None, 'valid_until': None}
             await update.message.reply_text(f"–ü–æ–¥–ø–∏—Å–∫–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {target_user_id} —Å–±—Ä–æ—à–µ–Ω–∞.")
             logger.info(f"Admin {update.effective_user.id} reset subscription for user {target_user_id}.")
        else:
            valid_until_date = (datetime.now() + timedelta(days=days)).strftime("%Y-%m-%d")
            all_user_subscriptions[target_user_id] = {
                'level': sub_level_key,
                'valid_until': valid_until_date
            }
            await update.message.reply_text(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {target_user_id} –≤—ã–¥–∞–Ω–∞ –ø–æ–¥–ø–∏—Å–∫–∞ '{sub_level_key}' –Ω–∞ {days} –¥–Ω–µ–π (–¥–æ {valid_until_date}).")
            logger.info(f"Admin {update.effective_user.id} granted subscription '{sub_level_key}' for {days} days to user {target_user_id}.")
        
        # await context.application.persist_bot_data() # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å

    except (IndexError, ValueError) as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö: {e}\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /grantsub <user_id> <level_key> <days>")
    except Exception as e_grant:
        logger.error(f"Error in grant_subscription_command: {e_grant}\n{traceback.format_exc()}")
        await update.message.reply_text(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–¥–∞—á–µ –ø–æ–¥–ø–∏—Å–∫–∏: {e_grant}")


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    user_id = update.effective_user.id if update.effective_user else "UnknownUser"
    logger.debug(f"handle_message: Received message from user {user_id}: '{user_message}'")

    if not user_message or not user_message.strip():
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–µ–ø—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å.", reply_markup=get_main_reply_keyboard())
        return

    current_model_key = get_current_model_key(context)
    selected_model_details = AVAILABLE_TEXT_MODELS[current_model_key]
    
    # –ò–ó–ú–ï–ù–ï–ù–û: system_prompt_text —Ç–µ–ø–µ—Ä—å –±–µ—Ä–µ—Ç—Å—è –∏–∑ get_current_mode_details, –∫–æ—Ç–æ—Ä–∞—è —É—á–∏—Ç—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å
    system_prompt_text = get_current_mode_details(context)["prompt"]
    logger.debug(f"Using system prompt for mode associated with {current_model_key}: '{get_current_mode_details(context)['name']}'")

    can_request, limit_message, _ = check_and_log_request_attempt(user_id, current_model_key, context)
    if not can_request:
        await update.message.reply_text(limit_message, reply_markup=get_main_reply_keyboard())
        logger.info(f"User {user_id} limit REJECTED for model_key {current_model_key}: {limit_message}")
        return
    logger.info(f"User {user_id} limit ACCEPTED for model_key {current_model_key}.")

    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
    
    reply_text = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞." 
    api_type = selected_model_details.get("api_type")
    request_successful = False

    if api_type == "google_genai":
        if not GOOGLE_GEMINI_API_KEY or "YOUR_GOOGLE_GEMINI_API_KEY" in GOOGLE_GEMINI_API_KEY or "AIzaSy" not in GOOGLE_GEMINI_API_KEY:
            reply_text = "–ö–ª—é—á API –¥–ª—è –º–æ–¥–µ–ª–µ–π Google Gemini –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
            logger.error("Google Gemini API key is not configured.")
        else:
            try:
                model_id_for_api = selected_model_details["id"]
                active_model = genai.GenerativeModel(model_id_for_api)
                logger.info(f"Using Google genai model: {model_id_for_api} for user {user_id}")
                
                generation_config_params = {"temperature": 0.75}
                if MAX_OUTPUT_TOKENS_GEMINI_LIB > 0 and model_id_for_api not in ["gemini-1.5-pro-latest", "gemini-1.5-flash-latest"]: # –ü—Ä–∏–º–µ—Ä: –¥–ª—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–µ —Å—Ç–∞–≤–∏–º
                    generation_config_params["max_output_tokens"] = MAX_OUTPUT_TOKENS_GEMINI_LIB
                generation_config = genai.types.GenerationConfig(**generation_config_params)
                
                chat_history = [
                    {"role": "user", "parts": [system_prompt_text]},
                    {"role": "model", "parts": ["–ü–æ–Ω—è–ª. –Ø –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å."]}
                ]
                chat = active_model.start_chat(history=chat_history)
                logger.debug(f"Sending to Google API. Model: {model_id_for_api}. System prompt (len {len(system_prompt_text)}): '{system_prompt_text[:100]}...', User message: '{user_message[:100]}'")
                response_gen = await chat.send_message_async(user_message, generation_config=generation_config)
                
                api_reply_text_google = response_gen.text

                prompt_tokens, completion_tokens = 0, 0
                if hasattr(response_gen, 'usage_metadata') and response_gen.usage_metadata:
                    usage = response_gen.usage_metadata
                    prompt_tokens = usage.prompt_token_count
                    completion_tokens = usage.candidates_token_count
                    logger.info(f"Google API Usage for {model_id_for_api}: Prompt Tokens: {prompt_tokens}, Completion Tokens: {completion_tokens}")
                    context.user_data.setdefault('api_token_usage', [])
                    context.user_data['api_token_usage'].append({
                        'timestamp': datetime.now().isoformat(),
                        'model': model_id_for_api,
                        'prompt_tokens': prompt_tokens,
                        'completion_tokens': completion_tokens,
                        'total_tokens': getattr(usage, 'total_token_count', prompt_tokens + completion_tokens)
                    })


                if not api_reply_text_google or not api_reply_text_google.strip():
                    block_reason_msg = ""
                    if hasattr(response_gen, 'prompt_feedback') and response_gen.prompt_feedback and response_gen.prompt_feedback.block_reason:
                        block_reason_msg = f" –ü—Ä–∏—á–∏–Ω–∞: {response_gen.prompt_feedback.block_reason}."
                    reply_text = f"–ò–ò (Google) –Ω–µ —Å–º–æ–≥ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ–Ω –±—ã–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω.{block_reason_msg} –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å."
                    logger.warning(f"Empty or blocked response from Google API. Model: {model_id_for_api}.{block_reason_msg}")
                else:
                    reply_text = api_reply_text_google
                    request_successful = True

            except google.api_core.exceptions.GoogleAPIError as e_google_api:
                error_message = str(e_google_api).lower()
                logger.error(f"GoogleAPIError for model {selected_model_details['id']}: {str(e_google_api)}\n{traceback.format_exc()}")
                reply_text = f"–û—à–∏–±–∫–∞ API Google Gemini: {type(e_google_api).__name__}."
                if "api key not valid" in error_message or "api key invalid" in error_message:
                    reply_text = "–û—à–∏–±–∫–∞: API –∫–ª—é—á –¥–ª—è Google –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
                elif "billing account" in error_message or "enable billing" in error_message:
                    reply_text = "–ü—Ä–æ–±–ª–µ–º–∞ —Å –±–∏–ª–ª–∏–Ω–≥–æ–º –¥–ª—è API Google. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
                elif "resource has been exhausted" in error_message: 
                    reply_text = "–ò—Å—á–µ—Ä–ø–∞–Ω–∞ –∫–≤–æ—Ç–∞ –¥–ª—è Google API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
                elif "user location" in error_message:
                     reply_text = "–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ —á–µ—Ä–µ–∑ Google API."
                elif "content filter" in error_message:
                    reply_text = "–ó–∞–ø—Ä–æ—Å –±—ã–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."


            except Exception as e_general_google:
                logger.error(f"General error processing Google Gemini model {selected_model_details['id']}: {str(e_general_google)}\n{traceback.format_exc()}")
                reply_text = "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ Google Gemini."

    elif api_type == "custom_http_api":
        api_key_var_name = selected_model_details.get("api_key_var_name")
        actual_api_key = globals().get(api_key_var_name)

        if not actual_api_key or ("sk-" not in actual_api_key and "pk-" not in actual_api_key) :
            reply_text = f"–ö–ª—é—á API –¥–ª—è '{selected_model_details['name']}' –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ."
            logger.warning(f"API key from var '{api_key_var_name}' is missing or invalid for Custom API. Key: {str(actual_api_key)[:10]}...")
        else:
            endpoint = selected_model_details["endpoint"]
            model_id_for_payload_api = selected_model_details["id"]
            
            messages_payload = [
                # –ò–ó–ú–ï–ù–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º "system" —Ä–æ–ª—å, –µ—Å–ª–∏ API –µ—ë –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, –∏–Ω–∞—á–µ - "user"
                # –î–ª—è gen-api.ru, –∫–∞–∫ –º—ã –≤—ã—è—Å–Ω–∏–ª–∏, –ø–µ—Ä–≤—ã–π "user" —ç—Ç–æ —Å–∏—Å—Ç–µ–º–Ω—ã–π.
                # –ï—Å–ª–∏ –±—ã API –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª–æ "system", –±—ã–ª–æ –±—ã: {"role": "system", "content": system_prompt_text},
                {"role": "user", "content": system_prompt_text}, 
                {"role": "user", "content": user_message}
            ]

            payload = {
                "model": model_id_for_payload_api,
                "messages": messages_payload,
                "is_sync": True,
                "temperature": selected_model_details.get("temperature", 0.75), # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –º–æ–¥–µ–ª–∏ –∏–ª–∏ 0.75
                "stream": False, # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –Ω–∞—à–ª–∏
                "n": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "top_p": 1,
                "response_format": json.dumps({"type": "text"}) 
            }
            
            headers = {
                'Content-Type': 'application/json',
                'Accept': 'application/json',
                'Authorization': f'Bearer {actual_api_key}'
            }
            logger.info(f"Sending request to Custom HTTP API. Endpoint: {endpoint}, Model in payload: {model_id_for_payload_api}")
            logger.debug(f"Custom API Payload: {json.dumps(payload, ensure_ascii=False)}")

            try:
                api_response = requests.post(endpoint, json=payload, headers=headers, timeout=90)
                logger.debug(f"Custom API response status: {api_response.status_code}")
                response_data = {}
                try:
                    response_data = api_response.json()
                    logger.debug(f"Custom API response body (JSON): {json.dumps(response_data, ensure_ascii=False, indent=2)}")
                except json.JSONDecodeError as e_json:
                    logger.error(f"Custom API response body (not JSON or decode error): {api_response.text}. Error: {e_json}")
                    reply_text = f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç Custom API ({selected_model_details['name']})."
                    raise 

                api_response.raise_for_status()

                if "response" in response_data and isinstance(response_data["response"], list) and len(response_data["response"]) > 0:
                    first_choice = response_data["response"][0]
                    if "message" in first_choice and "content" in first_choice["message"]:
                        api_reply_text_custom = first_choice["message"]["content"]
                        if api_reply_text_custom and api_reply_text_custom.strip():
                            reply_text = api_reply_text_custom
                            request_successful = True
                            if "cost" in response_data:
                                cost = response_data["cost"]
                                logger.info(f"Custom API request cost for {selected_model_details['name']}: {cost}")
                                context.user_data.setdefault('api_costs', [])
                                context.user_data['api_costs'].append({
                                    'timestamp': datetime.now().isoformat(),
                                    'model_key': current_model_key, # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á –º–æ–¥–µ–ª–∏
                                    'cost': cost 
                                })
                            req_id_resp = response_data.get("request_id")
                            model_resp = response_data.get("model")
                            logger.info(f"Custom API success: request_id={req_id_resp}, model_in_response='{model_resp}'")
                        else:
                            reply_text = f"–ò–ò ({selected_model_details['name']}) –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –≤ 'content'."
                            logger.warning(f"Custom API returned empty 'content' in message: {response_data}")
                    else:
                        reply_text = f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ 'message' –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç 'content' –≤ –æ—Ç–≤–µ—Ç–µ –æ—Ç Custom API ({selected_model_details['name']})."
                        logger.warning(f"Custom API: 'message' or 'content' field missing in first choice: {first_choice}. Full response: {response_data}")
                elif "detail" in response_data: 
                    reply_text = f"–û—à–∏–±–∫–∞ Custom API ({selected_model_details['name']}): {response_data['detail']}"
                    logger.error(f"Custom API returned error detail: {response_data['detail']}. Full response: {response_data}")
                else: 
                    reply_text = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Custom API ({selected_model_details['name']}). –û—Ç–≤–µ—Ç ({api_response.status_code}) –ø–æ–ª—É—á–µ–Ω, –Ω–æ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω."
                    logger.warning(f"Unexpected response structure from Custom API ({api_response.status_code}). Full response: {json.dumps(response_data, ensure_ascii=False)}")
            
            except requests.exceptions.HTTPError as e_http:
                error_content_str = "No details in response text."
                try: error_content_json = e_http.response.json(); error_content_str = json.dumps(error_content_json)
                except json.JSONDecodeError: error_content_str = e_http.response.text
                
                logger.error(f"HTTPError for Custom API '{selected_model_details['name']}': {e_http}. Status: {e_http.response.status_code}. Content: {error_content_str}")
                if e_http.response.status_code == 402:
                    reply_text = f"–û—à–∏–±–∫–∞ 402: –ü—Ä–æ–±–ª–µ–º–∞ —Å –æ–ø–ª–∞—Ç–æ–π –¥–ª—è Custom API ({selected_model_details['name']}). –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É API."
                elif e_http.response.status_code == 422:
                     reply_text = f"–û—à–∏–±–∫–∞ 422: –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ Custom API. –î–µ—Ç–∞–ª–∏: {error_content_str}"
                else:
                    reply_text = f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ ({e_http.response.status_code}) –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ '{selected_model_details['name']}'."
            except requests.exceptions.RequestException as e_req_custom:
                logger.error(f"RequestException for Custom API '{selected_model_details['name']}': {e_req_custom}")
                reply_text = f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ '{selected_model_details['name']}'. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            except Exception as e_custom_proc:
                logger.error(f"Error processing Custom API response for '{selected_model_details['name']}': {e_custom_proc}\n{traceback.format_exc()}")
                reply_text = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç '{selected_model_details['name']}'."
    else:
        reply_text = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø API: {api_type}"
        logger.error(f"Unsupported API type: {api_type} for model_key {current_model_key}")

    if request_successful and selected_model_details.get("is_limited"):
        increment_request_count(user_id, current_model_key, context)
            
    reply_text_for_sending, was_truncated = smart_truncate(reply_text, MAX_MESSAGE_LENGTH_TELEGRAM)
    await update.message.reply_text(reply_text_for_sending, reply_markup=get_main_reply_keyboard())
    if request_successful:
        logger.info(f"Sent successful response for model_key {current_model_key}. Truncated: {was_truncated}")


async def set_bot_commands(application: Application):
    commands = [
        BotCommand("start", "üöÄ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ / –ò–Ω—Ñ–æ"),
        BotCommand("mode", "üß† –°–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º –ò–ò"),
        BotCommand("model", "‚öôÔ∏è –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –ò–ò"),
        BotCommand("usage", "üìä –õ–∏–º–∏—Ç—ã / –ü–æ–¥–ø–∏—Å–∫–∞"),
        BotCommand("subscribe", "üíé –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–¥–ø–∏—Å–∫–∞—Ö"),
        BotCommand("help", "‚ÑπÔ∏è –ü–æ–º–æ—â—å"),
    ]
    if YOUR_ADMIN_ID: 
        commands.append(BotCommand("grantsub", "üîë –í—ã–¥–∞—Ç—å –ø–æ–¥–ø–∏—Å–∫—É (–∞–¥–º–∏–Ω)"))

    try:
        await application.bot.set_my_commands(commands)
        logger.info("Bot commands set successfully.")
    except Exception as e:
        logger.error(f"Failed to set bot commands: {e}")


async def main():
    if "YOUR_TELEGRAM_TOKEN" in TOKEN or not TOKEN or len(TOKEN.split(":")[0]) < 8:
        logger.critical("CRITICAL: TELEGRAM_TOKEN is not set correctly or is a placeholder.")
        return
    
    persistence = PicklePersistence(filepath="bot_user_data.pkl")

    application = Application.builder().token(TOKEN).persistence(persistence).build()

    await set_bot_commands(application) # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–º–∞–Ω–¥

    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("mode", select_mode_command))
    application.add_handler(CommandHandler("model", select_model_command))
    application.add_handler(CommandHandler("usage", usage_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("subscribe", subscribe_info_command)) 
    application.add_handler(CommandHandler("grantsub", grant_subscription_command))

    application.add_handler(MessageHandler(filters.Text(["ü§ñ –†–µ–∂–∏–º –ò–ò"]), select_mode_command))
    application.add_handler(MessageHandler(filters.Text(["‚öôÔ∏è –ú–æ–¥–µ–ª—å –ò–ò"]), select_model_command))
    application.add_handler(MessageHandler(filters.Text(["üìä –õ–∏–º–∏—Ç—ã / –ü–æ–¥–ø–∏—Å–∫–∞"]), usage_command))
    application.add_handler(MessageHandler(filters.Text(["‚ùì –ü–æ–º–æ—â—å"]), help_command))
    
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CallbackQueryHandler(button_callback))

    logger.info("Starting bot application...")
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ application.
        # run_polling –±–æ–ª–µ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª–µ–Ω –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω—ã —Å–ª–æ–∂–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ updater'–∞
        await application.run_polling()
        # –°—Ç–∞—Ä—ã–π –≤–∞—Ä–∏–∞–Ω—Ç (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω—É–∂–µ–Ω –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫, –Ω–æ run_polling –ø—Ä–æ—â–µ):
        # await application.initialize() 
        # await application.updater.start_polling()
        # await application.start()
        # logger.info("Bot started successfully and is polling for updates.")
        # await application.updater.idle() # –î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è run_polling
    except Exception as e_poll:
        logger.critical(f"Error during application startup or polling: {e_poll}\n{traceback.format_exc()}")
    # finally: # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è start() –∏ idle()
        # if application.updater and application.updater.is_running:
        #     await application.updater.stop()
        # await application.stop()
        # await application.shutdown()
        # logger.info("Bot stopped.")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Bot stopped by user (KeyboardInterrupt)")
    except Exception as e_main_run:
        logger.critical(f"Critical error in asyncio.run(main()): {e_main_run}\n{traceback.format_exc()}")
