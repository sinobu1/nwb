import telegram
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update # –î–æ–±–∞–≤–∏–ª ParseMode
from telegram.constants import ParseMode # –Ø–≤–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º ParseMode
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
import google.generativeai as genai
import requests 
import logging
import traceback
import os
import asyncio
import nest_asyncio

nest_asyncio.apply()
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

TOKEN = os.getenv("TELEGRAM_TOKEN", "8185454402:AAEgJLaBSaUSyP9Z_zv76Fn0PtEwltAqga0")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCdDMpgLJyz6aYdwT9q4sbBk7sHVID4BTI")
YANDEX_API_KEY = os.getenv("YANDEX_API_KEY", "YOUR_YANDEX_API_KEY")

MAX_OUTPUT_TOKENS_GEMINI = 1500
MAX_MESSAGE_LENGTH_TELEGRAM = 2500 # –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–º –¥–ª—è Markdown, –Ω–æ –±—É–¥–µ–º —Å—Ç—Ä–µ–º–∏—Ç—å—Å—è –∫ –º–µ–Ω—å—à–µ–º—É

# --- –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´ —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –¥–ª–∏–Ω–µ ---
AI_MODES = {
    "universal_ai": {
        "name": "ü§ñ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò",
        "prompt": (
            "–¢—ã ‚Äî Gemini, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç Google. "
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏: –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, "
            "–¥–∞–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –≤—ã–ø–æ–ª–Ω—è—Ç—å –∞–Ω–∞–ª–∏–∑ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —à–∏—Ä–æ–∫–æ–º—É –∫—Ä—É–≥—É —Ç–µ–º. "
            "–ë—É–¥—å –≤–µ–∂–ª–∏–≤, –æ–±—ä–µ–∫—Ç–∏–≤–µ–Ω, —Ç–æ—á–µ–Ω –∏ –ø–æ–ª–µ–∑–µ–Ω. –ï—Å–ª–∏ —Ç–≤–æ–∏ –∑–Ω–∞–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–π –æ–± —ç—Ç–æ–º. "
            "–ò–∑–±–µ–≥–∞–π –ª–∏—á–Ω—ã—Ö –º–Ω–µ–Ω–∏–π, –µ—Å–ª–∏ —Ç–µ–±—è –æ–± —ç—Ç–æ–º –Ω–µ –ø—Ä–æ—Å—è—Ç.\n\n"
            "**–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π Markdown –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏: **–¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è** –∏—Å–ø–æ–ª—å–∑—É–π –¥–≤–æ–π–Ω—ã–µ –∑–≤–µ–∑–¥–æ—á–∫–∏, *–¥–ª—è –∫—É—Ä—Å–∏–≤–∞* ‚Äî –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ. "
            "–°–ø–∏—Å–∫–∏ –æ—Ñ–æ—Ä–º–ª—è–π –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—É–Ω–∫—Ç–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `1. –ü–µ—Ä–≤—ã–π –ø—É–Ω–∫—Ç`). "
            "–î–ª—è —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∫–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π `–æ–±—Ä–∞—Ç–Ω—ã–µ –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã`.\n\n"
            "**–î–ª–∏–Ω–∞ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç—å:** –°—Ç–∞—Ä–∞–π—Å—è, —á—Ç–æ–±—ã —Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –±—ã–ª–∏ –ø–æ–ª–Ω—ã–º–∏ –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–º–∏. "
            "–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–∫–∏ –∏–ª–∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è, —É–±–µ–¥–∏—Å—å, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—É–Ω–∫—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞—Å–∫—Ä—ã—Ç. "
            "–ï—Å–ª–∏ —á—É–≤—Å—Ç–≤—É–µ—à—å, —á—Ç–æ –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º (–±–æ–ª—å—à–µ 4-5 –∞–±–∑–∞—Ü–µ–≤ –∏–ª–∏ 7-10 –ø—É–Ω–∫—Ç–æ–≤ —Å–ø–∏—Å–∫–∞), "
            "–ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –µ–≥–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—É—Ç—å, –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–∞–∑–±–∏—Ç—å –≤–æ–ø—Ä–æ—Å –Ω–∞ —á–∞—Å—Ç–∏. "
            "–ü—Ä–µ–¥–ø–æ—á—Ç–∏ –¥–∞—Ç—å –Ω–∞ –æ–¥–∏–Ω –ø—É–Ω–∫—Ç –º–µ–Ω—å—à–µ, –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é, —á–µ–º –æ–±–æ—Ä–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π."
        ),
        "welcome": "–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ä–µ–∂–∏–º '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò'. –ö–∞–∫–æ–π —É –≤–∞—Å –∑–∞–ø—Ä–æ—Å?"
    },
    "creative_helper": {
        "name": "‚úçÔ∏è –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ü–æ–º–æ—â–Ω–∏–∫",
        "prompt": (
            "–¢—ã ‚Äî Gemini, –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ò–ò-–ø–∞—Ä—Ç–Ω—ë—Ä –∏ –ø–∏—Å–∞—Ç–µ–ª—å. "
            "–ü–æ–º–æ–≥–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–¥–µ–∏, –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç—ã (—Ä–∞—Å—Å–∫–∞–∑—ã, —Å—Ç–∏—Ö–∏, —Å—Ü–µ–Ω–∞—Ä–∏–∏, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã), "
            "–ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å —Å–ª–æ–≥–∞–Ω—ã, —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ —Ä–µ—à–∞—Ç—å –¥—Ä—É–≥–∏–µ —Ç–≤–æ—Ä—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏. "
            "–ë—É–¥—å –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–º, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–π –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã.\n\n"
            "**–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π Markdown –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –∏–¥–µ–π: **–¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–ª–∏ –∞–∫—Ü–µ–Ω—Ç–æ–≤** –∏—Å–ø–æ–ª—å–∑—É–π –¥–≤–æ–π–Ω—ã–µ –∑–≤–µ–∑–¥–æ—á–∫–∏, *–¥–ª—è –º–µ—Ç–∞—Ñ–æ—Ä –∏–ª–∏ —Ü–∏—Ç–∞—Ç* ‚Äî –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ. "
            "–ï—Å–ª–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å –≤–∞—Ä–∏–∞–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ª–æ–≥–∞–Ω—ã), –æ—Ñ–æ—Ä–º–ª—è–π –∏—Ö –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏ (`- –ü—Ä–∏–º–µ—Ä`).\n\n"
            "**–î–ª–∏–Ω–∞ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç—å:** –¢–≤–æ—Ä—á–µ—Å—Ç–≤–æ –Ω–µ –≤—Å–µ–≥–¥–∞ —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ —Ä–∞–º–∫–∏, –Ω–æ —Å—Ç–∞—Ä–∞–π—Å—è, —á—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—ã–ª —á–∏—Ç–∞–µ–º—ã–º. "
            "–ï—Å–ª–∏ —ç—Ç–æ –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞—Å—Å–∫–∞–∑), —É–±–µ–¥–∏—Å—å, —á—Ç–æ –æ–Ω –∏–º–µ–µ—Ç –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ. "
            "–ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –∏–¥–µ–π, –ø—É—Å—Ç—å –æ–Ω –±—É–¥–µ—Ç –ø–æ–ª–Ω—ã–º."
        ),
        "welcome": "–†–µ–∂–∏–º '–¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ü–æ–º–æ—â–Ω–∏–∫' –∫ –≤–∞—à–∏–º —É—Å–ª—É–≥–∞–º! –ù–∞–¥ –∫–∞–∫–æ–π —Ç–≤–æ—Ä—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–µ–π –ø–æ—Ä–∞–±–æ—Ç–∞–µ–º?"
    },
}
DEFAULT_AI_MODE_KEY = "universal_ai"

AVAILABLE_TEXT_MODELS = {
    "gemini_2_5_flash_preview": {
        "name": "üíé G-2.5 Flash Preview (04-17)",
        "id": "gemini-2.5-flash-preview-04-17"
    },
    "gemini_2_0_flash": {
        "name": "‚ö°Ô∏è G-2.0 Flash",
        "id": "gemini-2.0-flash"
    }
}
DEFAULT_MODEL_ID = AVAILABLE_TEXT_MODELS["gemini_2_5_flash_preview"]["id"]

try:
    genai.configure(api_key=GEMINI_API_KEY)
    logger.info("Gemini API configured successfully.")
except Exception as e:
    logger.error(f"Failed to configure Gemini API: {str(e)}")

def get_current_mode_details(context: ContextTypes.DEFAULT_TYPE) -> dict:
    mode_key = context.user_data.get('current_ai_mode', DEFAULT_AI_MODE_KEY)
    return AI_MODES.get(mode_key, AI_MODES[DEFAULT_AI_MODE_KEY])

def get_current_model_id(context: ContextTypes.DEFAULT_TYPE) -> str:
    return context.user_data.get('selected_model_id', DEFAULT_MODEL_ID)

def get_current_model_display_name(context: ContextTypes.DEFAULT_TYPE) -> str:
    selected_id = get_current_model_id(context)
    for model_info in AVAILABLE_TEXT_MODELS.values():
        if model_info["id"] == selected_id:
            return model_info["name"]
    return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"

# --- –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –£–ú–ù–û–ô –û–ë–†–ï–ó–ö–ò ---
def smart_truncate(text: str, max_length: int) -> tuple[str, bool]:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ max_length, —Å—Ç–∞—Ä–∞—è—Å—å –Ω–µ —Ä–≤–∞—Ç—å —Å–ª–æ–≤–∞ –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π_—Ç–µ–∫—Å—Ç, –±—ã–ª–∞_–ª–∏_–æ–±—Ä–µ–∑–∫–∞).
    """
    if len(text) <= max_length:
        return text, False

    suffix = "\n\n_(...–æ—Ç–≤–µ—Ç –±—ã–ª —Å–æ–∫—Ä–∞—â–µ–Ω)_"
    adjusted_max_length = max_length - len(suffix)
    
    if adjusted_max_length <= 0: # –ï—Å–ª–∏ –¥–∞–∂–µ —Å—É—Ñ—Ñ–∏–∫—Å –Ω–µ –≤–ª–µ–∑–∞–µ—Ç
        return text[:max_length-3] + "...", True 

    truncated_text = text[:adjusted_max_length]

    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —Ç–æ—á–∫—É —Å –ø—Ä–æ–±–µ–ª–æ–º
    possible_cut_points = []
    last_newline = truncated_text.rfind('\n')
    if last_newline != -1:
        possible_cut_points.append(last_newline)
    
    last_sentence_end_period = truncated_text.rfind('. ')
    if last_sentence_end_period != -1:
        possible_cut_points.append(last_sentence_end_period + 1) # –í–∫–ª—é—á–∞–µ–º —Ç–æ—á–∫—É

    last_sentence_end_quest = truncated_text.rfind('? ')
    if last_sentence_end_quest != -1:
        possible_cut_points.append(last_sentence_end_quest + 1)

    last_sentence_end_excl = truncated_text.rfind('! ')
    if last_sentence_end_excl != -1:
        possible_cut_points.append(last_sentence_end_excl + 1)

    if possible_cut_points:
        cut_at = max(possible_cut_points)
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º—ã –Ω–µ –æ–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–∏–º–≤–æ–ª - –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏)
        if cut_at > adjusted_max_length * 0.7 or len(possible_cut_points) == 1 and possible_cut_points[0] == last_newline: # –û–±—Ä–µ–∑–∞–µ–º –ø–æ –ø–µ—Ä–µ–Ω–æ—Å—É —Å—Ç—Ä–æ–∫–∏ –µ—Å–ª–∏ –æ–Ω –±–ª–∏–∑–∫–æ –∫ –∫–æ–Ω—Ü—É –∏–ª–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
             return text[:cut_at].strip() + suffix, True

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à–µ–π —Ç–æ—á–∫–∏, —Ä–µ–∂–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –ø—Ä–æ–±–µ–ª—É
    last_space = truncated_text.rfind(' ')
    if last_space != -1 and last_space > adjusted_max_length * 0.7:
        return text[:last_space].strip() + suffix, True
    
    # –°–∞–º—ã–π –∫—Ä–∞–π–Ω–∏–π —Å–ª—É—á–∞–π - –∂–µ—Å—Ç–∫–∞—è –æ–±—Ä–µ–∑–∫–∞
    return text[:adjusted_max_length].strip() + suffix, True


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.setdefault('current_ai_mode', DEFAULT_AI_MODE_KEY)
    context.user_data.setdefault('selected_model_id', DEFAULT_MODEL_ID)
    current_mode = get_current_mode_details(context)
    current_model_name = get_current_model_display_name(context)
    await update.message.reply_text(
        f"–ü—Ä–∏–≤–µ—Ç! –Ø –º–Ω–æ–≥–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ò–ò-–±–æ—Ç.\n\n"
        f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: *{current_mode['name']}*\n"
        f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: *{current_model_name}*\n\n"
        "–í—ã –º–æ–∂–µ—Ç–µ:\n"
        "‚ñ´Ô∏è –ó–∞–¥–∞–≤–∞—Ç—å –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –¥–∞–≤–∞—Ç—å –∑–∞–¥–∞–Ω–∏—è.\n"
        "‚ñ´Ô∏è –°–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: /mode\n"
        "‚ñ´Ô∏è –í—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –ò–ò: /model\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å!",
        parse_mode=ParseMode.MARKDOWN_V2 # –ò—Å–ø–æ–ª—å–∑—É–µ–º MarkdownV2
    )

async def select_mode(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton(details["name"], callback_data=f"set_mode_{key}")] for key, details in AI_MODES.items()]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –¥–ª—è –ò–ò:', reply_markup=reply_markup)

async def select_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton(details["name"], callback_data=f"set_model_{key}")] for key, details in AVAILABLE_TEXT_MODELS.items()]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ò–ò –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:', reply_markup=reply_markup)

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    if data.startswith("set_mode_"):
        mode_key = data.split("set_mode_")[1]
        if mode_key in AI_MODES:
            context.user_data['current_ai_mode'] = mode_key
            mode_details = AI_MODES[mode_key]
            await query.edit_message_text(
                text=f"–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: *{mode_details['name']}*\n{telegram.helpers.escape_markdown(mode_details['welcome'], version=2)}", # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º Markdown –≤ welcome —Å–æ–æ–±—â–µ–Ω–∏–∏
                parse_mode=ParseMode.MARKDOWN_V2
            )
    elif data.startswith("set_model_"):
        model_key_in_dict = data.split("set_model_")[1]
        if model_key_in_dict in AVAILABLE_TEXT_MODELS:
            selected_model_info = AVAILABLE_TEXT_MODELS[model_key_in_dict]
            context.user_data['selected_model_id'] = selected_model_info["id"]
            await query.edit_message_text(
                text=f"–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: *{selected_model_info['name']}*",
                parse_mode=ParseMode.MARKDOWN_V2
            )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    user_id = update.message.from_user.id
    logger.info(f"Received message from {user_id}: '{user_message}'")

    current_mode_details = get_current_mode_details(context)
    system_prompt = current_mode_details["prompt"]
    selected_model_id = get_current_model_id(context)

    if context.user_data.get('current_ai_mode', DEFAULT_AI_MODE_KEY) == "universal_ai":
        # ... (–ª–æ–≥–∏–∫–∞ –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤, –µ—Å–ª–∏ –Ω—É–∂–Ω–∞)
        pass # –£–±—Ä–∞–ª –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏, –º–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –∏–ª–∏ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å

    if "—Ä–∞—Å—Å–∫–∞–∂–∏ —à—É—Ç–∫—É" in user_message.lower():
        # ... (–∫–æ–¥ –¥–ª—è —à—É—Ç–∫–∏)
        response_text = "–ü–æ—á–µ–º—É –∫–æ–º–ø—å—é—Ç–µ—Ä—ã –Ω–µ –ª—é–±—è—Ç —Ö–æ–¥–∏—Ç—å –Ω–∞ –ø–ª—è–∂? –ë–æ—è—Ç—Å—è, —á—Ç–æ —É –Ω–∏—Ö —Å—è–¥–µ—Ç *–±–∞—Ç–∞—Ä–µ–π–∫–∞* –∏–ª–∏ –ø–æ–ø–∞–¥–µ—Ç *–ø–µ—Å–æ–∫* –≤ –ø–æ—Ä—Ç—ã! üòÑ"
        try:
            await update.message.reply_text(response_text, parse_mode=ParseMode.MARKDOWN_V2)
        except telegram.error.BadRequest:
            await update.message.reply_text(telegram.helpers.escape_markdown(response_text, version=2)) # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ Markdown –Ω–µ —É–¥–∞–ª—Å—è
        return

    try:
        active_gemini_model = genai.GenerativeModel(selected_model_id)
        logger.info(f"Using Gemini model: {selected_model_id} for user {user_id}")
        
        generation_config = genai.types.GenerationConfig(
            max_output_tokens=MAX_OUTPUT_TOKENS_GEMINI,
            temperature=0.75
        )
        chat_history = [
            {"role": "user", "parts": [system_prompt]},
            {"role": "model", "parts": [telegram.helpers.escape_markdown(current_mode_details.get("welcome", "–•–æ—Ä–æ—à–æ, —è –≥–æ—Ç–æ–≤."), version=2)]} # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º Markdown –≤ "welcome" –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
        ]
        chat = active_gemini_model.start_chat(history=chat_history)
        response_gen = await chat.send_message_async(user_message, generation_config=generation_config)

        logger.debug(f"Raw Gemini response object: {response_gen}")
        # ... (–¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ Gemini, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)

        reply_text = response_gen.text
        
        if not reply_text or not reply_text.strip():
            logger.warning(f"Gemini returned empty text. Model: {selected_model_id}, User msg: '{user_message}'. Finish_reason: {response_gen.candidates[0].finish_reason if response_gen.candidates else 'N/A'}")
            reply_text = "–ò–ò –Ω–µ —Å–º–æ–≥ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ–Ω –±—ã–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å."
        
        # --- –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –£–ú–ù–û–ô –û–ë–†–ï–ó–ö–ò ---
        reply_text, was_truncated = smart_truncate(reply_text, MAX_MESSAGE_LENGTH_TELEGRAM)
        if was_truncated:
            logger.info(f"Gemini response was smartly truncated. Original length: {len(response_gen.text)}, Truncated length: {len(reply_text)}")

        # --- –û–¢–ü–†–ê–í–ö–ê –° MARKDOWN ---
        try:
            await update.message.reply_text(reply_text, parse_mode=ParseMode.MARKDOWN_V2)
            logger.info(f"Sent Gemini response with MarkdownV2 (model: {selected_model_id}, length: {len(reply_text)})")
        except telegram.error.BadRequest as e_markdown:
            logger.warning(f"Failed to send message with MarkdownV2: {e_markdown}. Sending as plain text.")
            # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–≤ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ "–æ–ø–∞—Å–Ω—ã–µ" –¥–ª—è Markdown —Å–∏–º–≤–æ–ª—ã,
            # –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –º–æ–¥–µ–ª—å—é, –Ω–æ –Ω–µ–≤–µ—Ä–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞–Ω—ã Telegram.
            # –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å reply_text –±–µ–∑ parse_mode, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ù–ï –¥–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Markdown.
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –î–û–õ–ñ–ù–ê –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Markdown, —Ç–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É–±—å–µ—Ç –µ–≥–æ.
            # –õ—É—á—à–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π reply_text –±–µ–∑ parse_mode.
            plain_text_reply = response_gen.text # –ë–µ—Ä–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç Gemini
            plain_text_reply, _ = smart_truncate(plain_text_reply, MAX_MESSAGE_LENGTH_TELEGRAM) # –û–±—Ä–µ–∑–∞–µ–º –µ–≥–æ —Ç–æ–∂–µ
            await update.message.reply_text(plain_text_reply) # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ parse_mode
            logger.info(f"Sent Gemini response as plain text after Markdown failure (model: {selected_model_id}, length: {len(plain_text_reply)})")

    except Exception as e:
        logger.error(f"Error during Gemini interaction or message handling: {str(e)}\n{traceback.format_exc()}")
        await update.message.reply_text(
            f"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å –º–æ–¥–µ–ª—å—é {get_current_model_display_name(context)}. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ —Å–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å/—Ä–µ–∂–∏–º."
        )

async def main():
    if "–í–ê–®_–¢–ï–õ–ï–ì–†–ê–ú_–¢–û–ö–ï–ù" in TOKEN or not TOKEN: # etc.
        logger.critical("CRITICAL: TELEGRAM_TOKEN is not set or uses a placeholder.")
        return
    if "–í–ê–®_GEMINI_API_–ö–õ–Æ–ß" in GEMINI_API_KEY or not GEMINI_API_KEY:
        logger.critical("CRITICAL: GEMINI_API_KEY is not set or uses a placeholder.")
        return
        
    application = Application.builder().token(TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler(["mode", "select_mode"], select_mode))
    application.add_handler(CommandHandler(["model", "select_model"], select_model))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CallbackQueryHandler(button_callback))

    logger.info("Starting bot with enhanced formatting and truncation...")
    await application.run_polling()

if __name__ == "__main__":
    asyncio.run(main())
