import telegram
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
import google.generativeai as genai
import requests # –î–ª—è –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç
import logging
import traceback
import os
import asyncio
import nest_asyncio

# Apply nest_asyncio to allow nested event loops
nest_asyncio.apply()

# Setup logging
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# Telegram Bot Token
TOKEN = os.getenv("TELEGRAM_TOKEN", "8185454402:AAEgJLaBSaUSyP9Z_zv76Fn0PtEwltAqga0") # –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –í–ê–® –¢–û–ö–ï–ù
# Gemini API Key
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCdDMpgLJyz6aYdwT9q4sbBk7sHVID4BTI") # –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –í–ê–® –ö–õ–Æ–ß
# Yandex Maps API Key
YANDEX_API_KEY = os.getenv("YANDEX_API_KEY", "YOUR_YANDEX_API_KEY") # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –∫–∞—Ä—Ç

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ë–û–¢–ê ---
MAX_OUTPUT_TOKENS_GEMINI = 1500 # –ö–∞–∫ –≤—ã –∏ –Ω–∞—Å—Ç—Ä–æ–∏–ª–∏
MAX_MESSAGE_LENGTH_TELEGRAM = 2000 # –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–ª, –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å (Telegram –ª–∏–º–∏—Ç 4096)

# --- –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´ (–±—ã–≤—à–∏–µ "–ª–∏—á–Ω–æ—Å—Ç–∏") ---
AI_MODES = {
    "universal_ai": {
        "name": "ü§ñ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò",
        "prompt": (
            "–¢—ã ‚Äî Gemini, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç Google. "
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏: –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, "
            "–¥–∞–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è, –≤—ã–ø–æ–ª–Ω—è—Ç—å –∞–Ω–∞–ª–∏–∑ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —à–∏—Ä–æ–∫–æ–º—É –∫—Ä—É–≥—É —Ç–µ–º. "
            "–ë—É–¥—å –≤–µ–∂–ª–∏–≤, –æ–±—ä–µ–∫—Ç–∏–≤–µ–Ω, —Ç–æ—á–µ–Ω –∏ –ø–æ–ª–µ–∑–µ–Ω. –ï—Å–ª–∏ —Ç–≤–æ–∏ –∑–Ω–∞–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–π –æ–± —ç—Ç–æ–º. "
            "–ò–∑–±–µ–≥–∞–π –ª–∏—á–Ω—ã—Ö –º–Ω–µ–Ω–∏–π, –µ—Å–ª–∏ —Ç–µ–±—è –æ–± —ç—Ç–æ–º –Ω–µ –ø—Ä–æ—Å—è—Ç."
        ),
        "welcome": "–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ä–µ–∂–∏–º '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò'. –ö–∞–∫–æ–π —É –≤–∞—Å –∑–∞–ø—Ä–æ—Å?"
    },
    "creative_helper": {
        "name": "‚úçÔ∏è –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ü–æ–º–æ—â–Ω–∏–∫",
        "prompt": (
            "–¢—ã ‚Äî Gemini, –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ò–ò-–ø–∞—Ä—Ç–Ω—ë—Ä –∏ –ø–∏—Å–∞—Ç–µ–ª—å. "
            "–ü–æ–º–æ–≥–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–¥–µ–∏, –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç—ã (—Ä–∞—Å—Å–∫–∞–∑—ã, —Å—Ç–∏—Ö–∏, —Å—Ü–µ–Ω–∞—Ä–∏–∏, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã), "
            "–ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å —Å–ª–æ–≥–∞–Ω—ã, —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ —Ä–µ—à–∞—Ç—å –¥—Ä—É–≥–∏–µ —Ç–≤–æ—Ä—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏. "
            "–ë—É–¥—å –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–º, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–π –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã."
        ),
        "welcome": "–†–µ–∂–∏–º '–¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ü–æ–º–æ—â–Ω–∏–∫' –∫ –≤–∞—à–∏–º —É—Å–ª—É–≥–∞–º! –ù–∞–¥ –∫–∞–∫–æ–π —Ç–≤–æ—Ä—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–µ–π –ø–æ—Ä–∞–±–æ—Ç–∞–µ–º?"
    },
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ —Ä–µ–∂–∏–º—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ç.–¥.
}
DEFAULT_AI_MODE_KEY = "universal_ai"

# --- –î–û–°–¢–£–ü–ù–´–ï –ú–û–î–ï–õ–ò GEMINI –î–õ–Ø –í–´–ë–û–†–ê ---
AVAILABLE_TEXT_MODELS = {
    "gemini_2_5_flash_preview": {
        "name": "üíé G-2.5 Flash Preview (04-17)", # –ë–æ–ª–µ–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ –∏–º—è –¥–ª—è –∫–Ω–æ–ø–∫–∏
        "id": "gemini-2.5-flash-preview-04-17"
    },
    "gemini_2_0_flash": {
        "name": "‚ö°Ô∏è G-2.0 Flash",
        "id": "gemini-2.0-flash"
    }
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å gemini-1.5-pro-latest –∏–ª–∏ gemini-1.5-flash-latest, –µ—Å–ª–∏ –æ–Ω–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –∏ –Ω—É–∂–Ω—ã
}
DEFAULT_MODEL_ID = AVAILABLE_TEXT_MODELS["gemini_2_5_flash_preview"]["id"] # –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini API (—Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è) ---
try:
    genai.configure(api_key=GEMINI_API_KEY)
    logger.info("Gemini API configured successfully.")
except Exception as e:
    logger.error(f"Failed to configure Gemini API: {str(e)}")
    # –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –±–æ—Ç –Ω–µ —Å–º–æ–∂–µ—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ Gemini

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
def get_current_mode_details(context: ContextTypes.DEFAULT_TYPE) -> dict:
    mode_key = context.user_data.get('current_ai_mode', DEFAULT_AI_MODE_KEY)
    return AI_MODES.get(mode_key, AI_MODES[DEFAULT_AI_MODE_KEY])

def get_current_model_id(context: ContextTypes.DEFAULT_TYPE) -> str:
    return context.user_data.get('selected_model_id', DEFAULT_MODEL_ID)

def get_current_model_display_name(context: ContextTypes.DEFAULT_TYPE) -> str:
    selected_id = get_current_model_id(context)
    for model_info in AVAILABLE_TEXT_MODELS.values():
        if model_info["id"] == selected_id:
            return model_info["name"]
    return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"


# --- –ö–û–ú–ê–ù–î–´ –ë–û–¢–ê ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.setdefault('current_ai_mode', DEFAULT_AI_MODE_KEY)
    context.user_data.setdefault('selected_model_id', DEFAULT_MODEL_ID)

    current_mode = get_current_mode_details(context)
    current_model_name = get_current_model_display_name(context)

    await update.message.reply_text(
        f"–ü—Ä–∏–≤–µ—Ç! –Ø –º–Ω–æ–≥–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ò–ò-–±–æ—Ç.\n\n"
        f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: *{current_mode['name']}*\n"
        f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: *{current_model_name}*\n\n"
        "–í—ã –º–æ–∂–µ—Ç–µ:\n"
        "‚ñ´Ô∏è –ó–∞–¥–∞–≤–∞—Ç—å –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –¥–∞–≤–∞—Ç—å –∑–∞–¥–∞–Ω–∏—è.\n"
        "‚ñ´Ô∏è –°–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: /mode\n"
        "‚ñ´Ô∏è –í—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –ò–ò: /model\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å!",
        parse_mode=telegram.constants.ParseMode.MARKDOWN
    )
    logger.info(f"Start command processed for user {update.message.from_user.id}")

async def select_mode(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton(details["name"], callback_data=f"set_mode_{key}")]
        for key, details in AI_MODES.items()
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –¥–ª—è –ò–ò:', reply_markup=reply_markup)

async def select_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton(details["name"], callback_data=f"set_model_{key}")] # key –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∫–ª—é—á –∏–∑ AVAILABLE_TEXT_MODELS
        for key, details in AVAILABLE_TEXT_MODELS.items()
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ò–ò –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:', reply_markup=reply_markup)

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data

    if data.startswith("set_mode_"):
        mode_key = data.split("set_mode_")[1]
        if mode_key in AI_MODES:
            context.user_data['current_ai_mode'] = mode_key
            mode_details = AI_MODES[mode_key]
            await query.edit_message_text(
                text=f"–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: *{mode_details['name']}*.\n{mode_details['welcome']}",
                parse_mode=telegram.constants.ParseMode.MARKDOWN
            )
            logger.info(f"User {query.from_user.id} changed AI mode to {mode_key}")
        else:
            await query.edit_message_text(text="–û—à–∏–±–∫–∞: –¢–∞–∫–æ–π —Ä–µ–∂–∏–º –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    elif data.startswith("set_model_"):
        model_key_in_dict = data.split("set_model_")[1] # –≠—Ç–æ –∫–ª—é—á –∏–∑ —Å–ª–æ–≤–∞—Ä—è AVAILABLE_TEXT_MODELS
        if model_key_in_dict in AVAILABLE_TEXT_MODELS:
            selected_model_info = AVAILABLE_TEXT_MODELS[model_key_in_dict]
            context.user_data['selected_model_id'] = selected_model_info["id"]
            await query.edit_message_text(
                text=f"–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: *{selected_model_info['name']}*.",
                parse_mode=telegram.constants.ParseMode.MARKDOWN
            )
            logger.info(f"User {query.from_user.id} changed AI model to {selected_model_info['id']}")
        else:
            await query.edit_message_text(text="–û—à–∏–±–∫–∞: –¢–∞–∫–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    user_id = update.message.from_user.id
    logger.info(f"Received message from {user_id}: '{user_message}'")

    current_mode_details = get_current_mode_details(context)
    system_prompt = current_mode_details["prompt"]
    selected_model_id = get_current_model_id(context)

    # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã –∏ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç—ã (–µ—Å–ª–∏ –∞–∫—Ç–∏–≤–µ–Ω —Ä–µ–∂–∏–º "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò")
    # –∏ –µ—Å–ª–∏ API –∫–ª—é—á –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
    if context.user_data.get('current_ai_mode', DEFAULT_AI_MODE_KEY) == "universal_ai":
        if "–≥–¥–µ –ø–æ–µ—Å—Ç—å –Ω–∞ —Ç–∞–≥–∞–Ω–∫–µ" in user_message.lower(): # –ü—Ä–∏–º–µ—Ä —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            response = "–ù–∞ –¢–∞–≥–∞–Ω–∫–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∫–∞—Ñ–µ! –ù–∞–ø—Ä–∏–º–µ—Ä, '–ì—Ä–∞–±–ª–∏' –¥–ª—è –±—é–¥–∂–µ—Ç–Ω–æ–≥–æ –æ–±–µ–¥–∞ –∏–ª–∏ '–¢–µ—Ä–µ–º–æ–∫'. –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–∞—à–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è (–∫—É—Ö–Ω—è, —Ü–µ–Ω–æ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω)."
            await update.message.reply_text(response)
            logger.info(f"Sent static response for universal_ai: {response}")
            return
        # ... (–¥—Ä—É–≥–∏–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã)

        # –ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞–º–∏ (–æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
        # –≠—Ç—É —á–∞—Å—Ç—å –º–æ–∂–Ω–æ –¥–æ—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–ª–∏ —É–±—Ä–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–∞
        if "–≥–¥–µ –ø–æ–µ—Å—Ç—å" in user_message.lower() and YANDEX_API_KEY != "YOUR_YANDEX_API_KEY":
            try:
                place_query = user_message.split("–≥–¥–µ –ø–æ–µ—Å—Ç—å")[-1].strip()
                if place_query.startswith("–Ω–∞ "): place_query = place_query[3:]
                if not place_query: place_query = "–ú–æ—Å–∫–≤–∞ —Ü–µ–Ω—Ç—Ä"
                
                search_text = f"–∫–∞—Ñ–µ {place_query}"
                api_url = f"https://search-maps.yandex.ru/v1/?text={requests.utils.quote(search_text)}&type=biz&lang=ru_RU&apikey={YANDEX_API_KEY}&results=1&rspn=1&ll=37.617700,55.755863&spn=0.552069,0.400552"
                
                response_maps = requests.get(api_url)
                response_maps.raise_for_status()
                data_maps = response_maps.json()
                
                if data_maps.get('features') and data_maps['features'][0].get('properties', {}).get('CompanyMetaData'):
                    place_name = data_maps['features'][0]['properties']['CompanyMetaData'].get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –º–µ—Å—Ç–æ')
                    place_address = data_maps['features'][0]['properties']['CompanyMetaData'].get('address', '')
                    response = f"–Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç: {place_name} ({place_address}). –†–µ–∫–æ–º–µ–Ω–¥—É—é —É—Ç–æ—á–Ω–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –ø–µ—Ä–µ–¥ –≤–∏–∑–∏—Ç–æ–º!"
                else:
                    response = f"–ù–µ —É–¥–∞–ª–æ—Å—å –±—ã—Å—Ç—Ä–æ –Ω–∞–π—Ç–∏ '{place_query}' —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å."
                await update.message.reply_text(response)
                logger.info(f"Sent Yandex response for universal_ai: {response}")
            except Exception as e_maps:
                logger.error(f"Yandex Maps error: {str(e_maps)}\n{traceback.format_exc()}")
                await update.message.reply_text("–í–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞–º.")
            return # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É, –µ—Å–ª–∏ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç—ã

    # –û–±—â–∏–µ –∫–æ–º–∞–Ω–¥—ã, –Ω–µ –∑–∞–≤–∏—Å—è—â–∏–µ –æ—Ç —Ä–µ–∂–∏–º–∞ (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å)
    if "—Ä–∞—Å—Å–∫–∞–∂–∏ —à—É—Ç–∫—É" in user_message.lower():
        response = "–ü–æ—á–µ–º—É –∫–æ–º–ø—å—é—Ç–µ—Ä—ã —Ç–∞–∫ —É–º–Ω—ã? –ü–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∏ —Å–ª—É—à–∞—é—Ç —Å–≤–æ—é –º–∞—Ç–µ—Ä–∏–Ω—Å–∫—É—é –ø–ª–∞—Ç—É! üòÑ"
        await update.message.reply_text(response)
        logger.info(f"Sent static joke response: {response}")
        return

    # --- –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Gemini ---
    try:
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±–æ—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        active_gemini_model = genai.GenerativeModel(selected_model_id)
        logger.info(f"Using Gemini model: {selected_model_id} for user {user_id}")
        
        generation_config = genai.types.GenerationConfig(
            max_output_tokens=MAX_OUTPUT_TOKENS_GEMINI,
            temperature=0.75 # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–æ–π
        )

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —á–∞—Ç–∞
        # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç, –≤—Ç–æ—Ä–æ–µ - "—Å–æ–≥–ª–∞—Å–∏–µ" –º–æ–¥–µ–ª–∏ (—É–ª—É—á—à–∞–µ—Ç —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º—Ç—É)
        chat_history = [
            {"role": "user", "parts": [system_prompt]},
            {"role": "model", "parts": [current_mode_details.get("welcome", "–•–æ—Ä–æ—à–æ, —è –≥–æ—Ç–æ–≤.")]}
        ]
        
        chat = active_gemini_model.start_chat(history=chat_history)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —á–∞—Ç
        response_gen = await chat.send_message_async(
            user_message,
            generation_config=generation_config
        )

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini (–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
        logger.debug(f"Raw Gemini response object: {response_gen}")
        if hasattr(response_gen, 'prompt_feedback') and response_gen.prompt_feedback:
            logger.debug(f"Gemini prompt feedback: {response_gen.prompt_feedback}")
        if hasattr(response_gen, 'candidates') and response_gen.candidates:
            logger.debug(f"Gemini candidates count: {len(response_gen.candidates)}")
            for i, candidate in enumerate(response_gen.candidates):
                logger.debug(f"Candidate {i} finish reason: {candidate.finish_reason}")
                logger.debug(f"Candidate {i} safety ratings: {candidate.safety_ratings}")

        reply = response_gen.text
        
        if not reply or not reply.strip():
            logger.warning(f"Gemini returned empty text. Model: {selected_model_id}, User msg: '{user_message}'. Finish_reason: {response_gen.candidates[0].finish_reason if response_gen.candidates else 'N/A'}")
            reply = "–ò–ò –Ω–µ —Å–º–æ–≥ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ–Ω –±—ã–ª –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å."
        
        if len(reply) > MAX_MESSAGE_LENGTH_TELEGRAM:
            reply = reply[:MAX_MESSAGE_LENGTH_TELEGRAM - 3] + "..."
            logger.info(f"Gemini response truncated to {MAX_MESSAGE_LENGTH_TELEGRAM} chars.")

        await update.message.reply_text(reply)
        logger.info(f"Sent Gemini response to user {user_id} (model: {selected_model_id}, length: {len(reply)})")

    except Exception as e:
        logger.error(f"Error during Gemini interaction or message handling: {str(e)}\n{traceback.format_exc()}")
        await update.message.reply_text(
            f"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å –º–æ–¥–µ–ª—å—é {get_current_model_display_name(context)}. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ —Å–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å/—Ä–µ–∂–∏–º."
        )

async def main():
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    if "–í–ê–®_–¢–ï–õ–ï–ì–†–ê–ú_–¢–û–ö–ï–ù" in TOKEN or not TOKEN:
        logger.critical("CRITICAL: TELEGRAM_TOKEN is not set or uses a placeholder. Please set your actual token.")
        return
    if "–í–ê–®_GEMINI_API_–ö–õ–Æ–ß" in GEMINI_API_KEY or not GEMINI_API_KEY:
        logger.critical("CRITICAL: GEMINI_API_KEY is not set or uses a placeholder. Please set your actual key.")
        # –ú–æ–∂–Ω–æ —Ä–∞–∑—Ä–µ—à–∏—Ç—å –∑–∞–ø—É—Å–∫ –±–µ–∑ Gemini –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π, –Ω–æ –ª—É—á—à–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å.
        # return 
        
    application = Application.builder().token(TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler(["mode", "select_mode"], select_mode)) # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–º–µ–Ω—ã —Ä–µ–∂–∏–º–∞
    application.add_handler(CommandHandler(["model", "select_model"], select_model)) # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏
    # application.add_handler(CommandHandler("premium", premium)) # –ï—Å–ª–∏ –±—É–¥–µ—Ç –ø—Ä–µ–º–∏—É–º
    
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CallbackQueryHandler(button_callback))

    logger.info("Starting bot with new concept...")
    try:
        await application.run_polling()
    except telegram.error.NetworkError as ne:
        logger.error(f"Telegram NetworkError: {ne}. Retrying might be necessary or check network.")
    except Exception as e_main:
        logger.error(f"Critical error in main polling loop: {e_main}\n{traceback.format_exc()}")


if __name__ == "__main__":
    asyncio.run(main())
